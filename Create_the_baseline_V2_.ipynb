{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdVzSh5ZifTE"
      },
      "source": [
        "# Clone on Github my edit to the CleanRL Github Repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Won7j1sbiY3D",
        "outputId": "eabbafc8-61f7-40b9-a19e-f80b51525e12"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    print(\"Running on Google Colab\")\n",
        "    !git clone https://github.com/Rami-Ismael/cleanrl.git\n",
        "else:\n",
        "    print(\"Not running on Google Colab\")\n",
        "\n",
        "# Set up warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\n",
        "    action='ignore',\n",
        "    category=DeprecationWarning,\n",
        "    module=r'.*'\n",
        ")\n",
        "warnings.filterwarnings(\n",
        "    action='default',\n",
        "    module=r'torch.ao.quantization'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRk_Wiz9inci"
      },
      "source": [
        "# Install dependencies for model evaluation ðŸ”½"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJ493P38io1U",
        "outputId": "bd05ce72-1be8-47fc-c1ca-4a719c2d8544"
      },
      "outputs": [],
      "source": [
        "if 'google.colab' in sys.modules:\n",
        "    print(\"Running on Google Colab\")\n",
        "    !apt-get install -y \\\n",
        "        libgl1-mesa-dev \\\n",
        "        libgl1-mesa-glx \\\n",
        "        libglew-dev \\\n",
        "        libosmesa6-dev \\\n",
        "        software-properties-common \\\n",
        "        patchelf \\\n",
        "        xvfb\n",
        "\n",
        "else:\n",
        "    print(\"Not running on Google Colab\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3mLO7WKis4l"
      },
      "source": [
        "# Install and import the packages ðŸ“¦"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LdNhXM_hiuwC",
        "outputId": "5da280b6-9468-4de8-8538-7a675082a0f3"
      },
      "outputs": [],
      "source": [
        "%%capture \n",
        "if 'google.colab' in sys.modules:\n",
        "    print(\"Running on Google Colab\")\n",
        "    !pip install -r /content/cleanrl/requirements/requirements.txt\n",
        "    !pip install -r /content/cleanrl/requirements/ppo_classic_control_tuning.txt\n",
        "    !pip install -r /content/cleanrl/requirements/requirements-pybullet.txt\n",
        "    !pip install huggingface-hub\n",
        "\n",
        "else:\n",
        "    print(\"Not running on Google Colab\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbsktsKjiwZN"
      },
      "source": [
        "# Check the Installation Processing\n",
        "- PyTorch should be 1.11\n",
        "- Weight and Bias should be Presnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-p01PzzAi1Gi",
        "outputId": "5cb1f023-8229-4824-9b26-da1c643359bf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import wandb\n",
        "import optuna\n",
        "print( \"Numpy\" , np.__version__)\n",
        "print(\"Weight and Bias Version\" , wandb.__version__)\n",
        "print( \"torch\" , torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYpu1_QRbkvw"
      },
      "source": [
        "# Set up Environment Variable for your Notebook "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQ_Y6N0f2Q0a",
        "outputId": "31025c54-c222-4bf7-fb49-a0ccc8631c4f"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "import os\n",
        "wandb.finish()\n",
        "wandb.login(key=\"594c8e9a35d34a66e52ac0a49c6e08fdefda3053\")\n",
        "os.environ[\"WANDB_API_KEY\"] = \"594c8e9a35d34a66e52ac0a49c6e08fdefda3053\"\n",
        "os.environ[\"HF_KEY\"] = \"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\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create the Train RL Agent with by calling the functional RL agent in your code base "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haIFAqd-bzve"
      },
      "source": [
        "# Create the Train DQN Model Free base model on classic control by calling the DRL with os.system\n",
        "## Param\n",
        "- [ x ] seed\n",
        "- [ x ] track\n",
        "- [ ] wandb_entity:compress_rl\n",
        "- [ ] wandb_project:\"cleanrl\"\n",
        "## Quantization\n",
        "https://discuss.pytorch.org/t/quantization-aware-training-8-bits-simulation/160538/5\n",
        "- Weigh are symmetrical Quantization\n",
        " $$min =  0  , max= 2^{bit-1}$$\n",
        " $$Quantization Scheme  affine$$\n",
        "- Activation are asymmetrical Quantization\n",
        "$$ min = 0 , max= 2^{bit-1}$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Cdexf_80JHB",
        "outputId": "c8bd093f-d52c-44ee-d34c-7e044eea497b"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "'''\n",
        "import time\n",
        "for env in [\"CartPole-v1\" , \"MountainCar-v0\" , \"Acrobot-v1\"]:\n",
        "  for seed in range( 0 , 3):\n",
        "    for optimizer in [ \"Adam\"  , \"Adan\" , \"hAdam\"]:\n",
        "      for bitwidth in [ 1 , 2 ,  4 ,  6 , 8]:\n",
        "        quantize_weight_bitwidth = bitwidth\n",
        "        quantize_weight_quantize_min =  ( 2 ** ( bitwidth - 1 ) ) * -1\n",
        "        quantize_weight_quantize_max = ( 2 ** ( bitwidth - 1 ) ) - 1\n",
        "        quantize_activation_bitwidth = bitwidth\n",
        "        quantize_activation_quantize_min = 0\n",
        "        quantize_activation_quantize_max = 2**(bitwidth) - 1 \n",
        "        print( type ( optimizer) )\n",
        "        print(f\"Where optimizer is {optimizer}\")\n",
        "        start_time = time.time()\n",
        "        if 'google.colab' in sys.modules:\n",
        "          os.system(f\"python cleanrl/cleanrl/dqn.py  --optimizer {optimizer} --track=True --seed={seed} --env={env} --quantize-weight-bitwidth={quantize_weight_bitwidth}  --quantize-weight-quantize-min={quantize_weight_quantize_min} --quantize-weight-quantize-max={quantize_weight_quantize_max} --quantize-activation-bitwidth={quantize_activation_bitwidth} --quantize-activation-quantize-min={quantize_activation_quantize_min} --quantize-activation-quantize-max={quantize_activation_quantize_max}\")\n",
        "        else:\n",
        "          os.system(f\"python cleanrl/dqn.py  --optimizer {optimizer} --track=True --seed={seed} --env={env} --quantize-weight-bitwidth={quantize_weight_bitwidth}  --quantize-weight-quantize-min={quantize_weight_quantize_min} --quantize-weight-quantize-max={quantize_weight_quantize_max} --quantize-activation-bitwidth={quantize_activation_bitwidth} --quantize-activation-quantize-min={quantize_activation_quantize_min} --quantize-activation-quantize-max={quantize_activation_quantize_max}\")\n",
        "        end_time = time.time()\n",
        "        print( \"Time taken to run the code\" , end_time - start_time)\n",
        "'''  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1o5jFLJw_lm"
      },
      "outputs": [],
      "source": [
        "#!cd cleanrl && python experiment/dqn-classic-control-no-sync.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create the Train a C51 Agent on Class Control"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture\n",
        "import time\n",
        "for env in [\"CartPole-v1\" , \"MountainCar-v0\" , \"Acrobot-v1\"]:\n",
        "  for seed in range( 0 , 3):\n",
        "    for optimizer in [ \"Adam\"  , \"Adan\" , \"hAdam\"]:\n",
        "      for bitwidth in [  2 ,  4 ,  6 , 8]:\n",
        "        quantize_weight_bitwidth = bitwidth\n",
        "        quantize_weight_quantize_min =  ( 2 ** ( bitwidth - 1 ) ) * -1\n",
        "        quantize_weight_quantize_max = ( 2 ** ( bitwidth - 1 ) ) - 1\n",
        "        quantize_activation_bitwidth = bitwidth\n",
        "        quantize_activation_quantize_min = 0\n",
        "        quantize_activation_quantize_max = 2**(bitwidth) - 1 \n",
        "        print( type ( optimizer) )\n",
        "        print(f\"Where optimizer is {optimizer}\")\n",
        "        start_time = time.time()\n",
        "        if 'google.colab' in sys.modules:\n",
        "          os.system(f\"python cleanrl/cleanrl/c51.py  --optimizer {optimizer} --track=True --seed={seed} --env={env} --quantize-weight-bitwidth={quantize_weight_bitwidth}  --quantize-weight-quantize-min={quantize_weight_quantize_min} --quantize-weight-quantize-max={quantize_weight_quantize_max} --quantize-activation-bitwidth={quantize_activation_bitwidth} --quantize-activation-quantize-min={quantize_activation_quantize_min} --quantize-activation-quantize-max={quantize_activation_quantize_max}\")\n",
        "        else:\n",
        "          os.system(f\"python cleanrl/c51.py  --optimizer {optimizer} --track=True --seed={seed} --env={env} --quantize-weight-bitwidth={quantize_weight_bitwidth}  --quantize-weight-quantize-min={quantize_weight_quantize_min} --quantize-weight-quantize-max={quantize_weight_quantize_max} --quantize-activation-bitwidth={quantize_activation_bitwidth} --quantize-activation-quantize-min={quantize_activation_quantize_min} --quantize-activation-quantize-max={quantize_activation_quantize_max}\")\n",
        "        end_time = time.time()\n",
        "        print( \"Time taken to run the code\" , end_time - start_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# References\n",
        "[1] https://pytorch.org/blog/quantization-in-practice/"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.7.13 ('cleanrl')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "3b8210207dea593cd78a47d19ab578efef95523f0b438f1eecba204cd30d51d3"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
