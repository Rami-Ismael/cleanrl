{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from rich import print\n",
    "\n",
    "## list all the atari gym environments\n",
    "env_names = [env_spec.id for env_spec in gym.envs.registry.all()]\n",
    "# print( env_names )\n",
    "## print all the envs name with atari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/null/miniconda3/envs/cleanrl/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/null/miniconda3/envs/cleanrl/lib/python3.7/site-packages/torch/utils/tensorboard/__init__.py:5: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  tensorboard.__version__\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Sequential</span><span style=\"font-weight: bold\">(</span>\n",
       "  <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ReLU</span><span style=\"font-weight: bold\">()</span>\n",
       "  <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m5\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m5\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m5\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from stable_baselines3.common.buffers import ReplayBuffer\n",
    "model = nn.Sequential(\n",
    "    nn.Linear( 5 , 5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear( 5 , 10 ))\n",
    "from rich import print\n",
    "print( model )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m5\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m5\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-2.0911e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-4.4193e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.9880e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.4006e-01</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.1163e-02</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-4.3219e-01</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.8718e-04</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-2.8189e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-6.3825e-02</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-4.2294e-01</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.2263e-01</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.8390e-01</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.4258e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.5691e-02</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.0865e-01</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.9293e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-2.6274e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-2.7591e-01</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.6678e-01</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.8082e-01</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.4296e-02</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.6439e-01</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.3404e-01</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.0173e-01</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.3472e-01</span><span style=\"font-weight: bold\">]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m-2.0911e-01\u001b[0m, \u001b[1;36m-4.4193e-01\u001b[0m, \u001b[1;36m-1.9880e-01\u001b[0m, \u001b[1;36m-1.4006e-01\u001b[0m,  \u001b[1;36m1.1163e-02\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m-4.3219e-01\u001b[0m,  \u001b[1;36m1.8718e-04\u001b[0m, \u001b[1;36m-2.8189e-01\u001b[0m, \u001b[1;36m-6.3825e-02\u001b[0m, \u001b[1;36m-4.2294e-01\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m \u001b[1;36m3.2263e-01\u001b[0m,  \u001b[1;36m1.8390e-01\u001b[0m,  \u001b[1;36m2.4258e-01\u001b[0m, \u001b[1;36m-1.5691e-02\u001b[0m, \u001b[1;36m-1.0865e-01\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m-1.9293e-01\u001b[0m, \u001b[1;36m-2.6274e-01\u001b[0m, \u001b[1;36m-2.7591e-01\u001b[0m,  \u001b[1;36m1.6678e-01\u001b[0m,  \u001b[1;36m2.8082e-01\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m \u001b[1;36m1.4296e-02\u001b[0m,  \u001b[1;36m3.6439e-01\u001b[0m,  \u001b[1;36m3.3404e-01\u001b[0m,  \u001b[1;36m3.0173e-01\u001b[0m,  \u001b[1;36m3.3472e-01\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0282</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2211</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0189</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.4369</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0341</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m-0.0282\u001b[0m,  \u001b[1;36m0.2211\u001b[0m, \u001b[1;36m-0.0189\u001b[0m, \u001b[1;36m-0.4369\u001b[0m, \u001b[1;36m-0.0341\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print( model[0])\n",
    "print( model[0].weight.data)\n",
    "print( model[0].bias.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">torch.quint8\n",
       "</pre>\n"
      ],
      "text/plain": [
       "torch.quint8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">class</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'torch.ao.quantization.observer.MovingAverageMinMaxObserver'</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m\u001b[32m'torch.ao.quantization.observer.MovingAverageMinMaxObserver'\u001b[0m\u001b[1m>\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print( getattr( torch ,  \"quint8\"))\n",
    "print( getattr( torch.ao.quantization ,  \"MovingAverageMinMaxObserver\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Sequential</span><span style=\"font-weight: bold\">(</span>\n",
       "  <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">QuantStub</span><span style=\"font-weight: bold\">()</span>\n",
       "  <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ReLU</span><span style=\"font-weight: bold\">()</span>\n",
       "  <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">DeQuantStub</span><span style=\"font-weight: bold\">()</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mQuantStub\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m5\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m5\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m5\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mDeQuantStub\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/null/miniconda3/envs/cleanrl/lib/python3.7/site-packages/torch/ao/quantization/observer.py:216: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  reduce_range will be deprecated in a future release of PyTorch.\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Sequential</span><span style=\"font-weight: bold\">(</span>\n",
       "  <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">QuantStub</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"font-weight: bold\">(</span>activation_post_process<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">FusedMovingAvgObsFakeQuantize</span><span style=\"font-weight: bold\">(</span>\n",
       "      <span style=\"color: #808000; text-decoration-color: #808000\">fake_quant_enabled</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">])</span>, <span style=\"color: #808000; text-decoration-color: #808000\">observer_enabled</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">])</span>, <span style=\"color: #808000; text-decoration-color: #808000\">scale</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>.<span style=\"font-weight: bold\">])</span>, <span style=\"color: #808000; text-decoration-color: #808000\">zero_point</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]</span>, \n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">dtype</span>=<span style=\"color: #800080; text-decoration-color: #800080\">torch</span>.int32<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dtype</span>=<span style=\"color: #800080; text-decoration-color: #800080\">torch</span>.quint8, <span style=\"color: #808000; text-decoration-color: #808000\">quant_min</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">quant_max</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">127</span>, <span style=\"color: #808000; text-decoration-color: #808000\">qscheme</span>=<span style=\"color: #800080; text-decoration-color: #800080\">torch</span>.per_tensor_affine, \n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">reduce_range</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "      <span style=\"font-weight: bold\">(</span>activation_post_process<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MovingAverageMinMaxObserver</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">min_val</span>=<span style=\"color: #800080; text-decoration-color: #800080\">inf</span>, <span style=\"color: #808000; text-decoration-color: #808000\">max_val</span>=-inf<span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "    <span style=\"font-weight: bold\">(</span>weight_fake_quant<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">FusedMovingAvgObsFakeQuantize</span><span style=\"font-weight: bold\">(</span>\n",
       "      <span style=\"color: #808000; text-decoration-color: #808000\">fake_quant_enabled</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">])</span>, <span style=\"color: #808000; text-decoration-color: #808000\">observer_enabled</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">])</span>, <span style=\"color: #808000; text-decoration-color: #808000\">scale</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>.<span style=\"font-weight: bold\">])</span>, <span style=\"color: #808000; text-decoration-color: #808000\">zero_point</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]</span>, \n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">dtype</span>=<span style=\"color: #800080; text-decoration-color: #800080\">torch</span>.int32<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dtype</span>=<span style=\"color: #800080; text-decoration-color: #800080\">torch</span>.qint8, <span style=\"color: #808000; text-decoration-color: #808000\">quant_min</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">quant_max</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">127</span>, <span style=\"color: #808000; text-decoration-color: #808000\">qscheme</span>=<span style=\"color: #800080; text-decoration-color: #800080\">torch</span>.per_channel_symmetric, \n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">reduce_range</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "      <span style=\"font-weight: bold\">(</span>activation_post_process<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MovingAveragePerChannelMinMaxObserver</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">min_val</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([])</span>, <span style=\"color: #808000; text-decoration-color: #808000\">max_val</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([]))</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">(</span>activation_post_process<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">FusedMovingAvgObsFakeQuantize</span><span style=\"font-weight: bold\">(</span>\n",
       "      <span style=\"color: #808000; text-decoration-color: #808000\">fake_quant_enabled</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">])</span>, <span style=\"color: #808000; text-decoration-color: #808000\">observer_enabled</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">])</span>, <span style=\"color: #808000; text-decoration-color: #808000\">scale</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>.<span style=\"font-weight: bold\">])</span>, <span style=\"color: #808000; text-decoration-color: #808000\">zero_point</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]</span>, \n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">dtype</span>=<span style=\"color: #800080; text-decoration-color: #800080\">torch</span>.int32<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dtype</span>=<span style=\"color: #800080; text-decoration-color: #800080\">torch</span>.quint8, <span style=\"color: #808000; text-decoration-color: #808000\">quant_min</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">quant_max</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">127</span>, <span style=\"color: #808000; text-decoration-color: #808000\">qscheme</span>=<span style=\"color: #800080; text-decoration-color: #800080\">torch</span>.per_tensor_affine, \n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">reduce_range</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "      <span style=\"font-weight: bold\">(</span>activation_post_process<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MovingAverageMinMaxObserver</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">min_val</span>=<span style=\"color: #800080; text-decoration-color: #800080\">inf</span>, <span style=\"color: #808000; text-decoration-color: #808000\">max_val</span>=-inf<span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ReLU</span><span style=\"font-weight: bold\">()</span>\n",
       "  <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "    <span style=\"font-weight: bold\">(</span>weight_fake_quant<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">FusedMovingAvgObsFakeQuantize</span><span style=\"font-weight: bold\">(</span>\n",
       "      <span style=\"color: #808000; text-decoration-color: #808000\">fake_quant_enabled</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">])</span>, <span style=\"color: #808000; text-decoration-color: #808000\">observer_enabled</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">])</span>, <span style=\"color: #808000; text-decoration-color: #808000\">scale</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>.<span style=\"font-weight: bold\">])</span>, <span style=\"color: #808000; text-decoration-color: #808000\">zero_point</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]</span>, \n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">dtype</span>=<span style=\"color: #800080; text-decoration-color: #800080\">torch</span>.int32<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dtype</span>=<span style=\"color: #800080; text-decoration-color: #800080\">torch</span>.qint8, <span style=\"color: #808000; text-decoration-color: #808000\">quant_min</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">quant_max</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">127</span>, <span style=\"color: #808000; text-decoration-color: #808000\">qscheme</span>=<span style=\"color: #800080; text-decoration-color: #800080\">torch</span>.per_channel_symmetric, \n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">reduce_range</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "      <span style=\"font-weight: bold\">(</span>activation_post_process<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MovingAveragePerChannelMinMaxObserver</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">min_val</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([])</span>, <span style=\"color: #808000; text-decoration-color: #808000\">max_val</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([]))</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">(</span>activation_post_process<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">FusedMovingAvgObsFakeQuantize</span><span style=\"font-weight: bold\">(</span>\n",
       "      <span style=\"color: #808000; text-decoration-color: #808000\">fake_quant_enabled</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">])</span>, <span style=\"color: #808000; text-decoration-color: #808000\">observer_enabled</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">])</span>, <span style=\"color: #808000; text-decoration-color: #808000\">scale</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>.<span style=\"font-weight: bold\">])</span>, <span style=\"color: #808000; text-decoration-color: #808000\">zero_point</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]</span>, \n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">dtype</span>=<span style=\"color: #800080; text-decoration-color: #800080\">torch</span>.int32<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dtype</span>=<span style=\"color: #800080; text-decoration-color: #800080\">torch</span>.quint8, <span style=\"color: #808000; text-decoration-color: #808000\">quant_min</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">quant_max</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">127</span>, <span style=\"color: #808000; text-decoration-color: #808000\">qscheme</span>=<span style=\"color: #800080; text-decoration-color: #800080\">torch</span>.per_tensor_affine, \n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">reduce_range</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "      <span style=\"font-weight: bold\">(</span>activation_post_process<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MovingAverageMinMaxObserver</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">min_val</span>=<span style=\"color: #800080; text-decoration-color: #800080\">inf</span>, <span style=\"color: #808000; text-decoration-color: #808000\">max_val</span>=-inf<span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">DeQuantStub</span><span style=\"font-weight: bold\">()</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mQuantStub\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mactivation_post_process\u001b[1m)\u001b[0m: \u001b[1;35mFusedMovingAvgObsFakeQuantize\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[33mfake_quant_enabled\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mobserver_enabled\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mscale\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m.\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mzero_point\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m, \n",
       "\u001b[33mdtype\u001b[0m=\u001b[35mtorch\u001b[0m.int32\u001b[1m)\u001b[0m, \u001b[33mdtype\u001b[0m=\u001b[35mtorch\u001b[0m.quint8, \u001b[33mquant_min\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mquant_max\u001b[0m=\u001b[1;36m127\u001b[0m, \u001b[33mqscheme\u001b[0m=\u001b[35mtorch\u001b[0m.per_tensor_affine, \n",
       "\u001b[33mreduce_range\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
       "      \u001b[1m(\u001b[0mactivation_post_process\u001b[1m)\u001b[0m: \u001b[1;35mMovingAverageMinMaxObserver\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmin_val\u001b[0m=\u001b[35minf\u001b[0m, \u001b[33mmax_val\u001b[0m=-inf\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33min_features\u001b[0m=\u001b[1;36m5\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m5\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
       "    \u001b[1m(\u001b[0mweight_fake_quant\u001b[1m)\u001b[0m: \u001b[1;35mFusedMovingAvgObsFakeQuantize\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[33mfake_quant_enabled\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mobserver_enabled\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mscale\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m.\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mzero_point\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m, \n",
       "\u001b[33mdtype\u001b[0m=\u001b[35mtorch\u001b[0m.int32\u001b[1m)\u001b[0m, \u001b[33mdtype\u001b[0m=\u001b[35mtorch\u001b[0m.qint8, \u001b[33mquant_min\u001b[0m=\u001b[1;36m-128\u001b[0m, \u001b[33mquant_max\u001b[0m=\u001b[1;36m127\u001b[0m, \u001b[33mqscheme\u001b[0m=\u001b[35mtorch\u001b[0m.per_channel_symmetric, \n",
       "\u001b[33mreduce_range\u001b[0m=\u001b[3;91mFalse\u001b[0m\n",
       "      \u001b[1m(\u001b[0mactivation_post_process\u001b[1m)\u001b[0m: \u001b[1;35mMovingAveragePerChannelMinMaxObserver\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmin_val\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mmax_val\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mactivation_post_process\u001b[1m)\u001b[0m: \u001b[1;35mFusedMovingAvgObsFakeQuantize\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[33mfake_quant_enabled\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mobserver_enabled\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mscale\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m.\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mzero_point\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m, \n",
       "\u001b[33mdtype\u001b[0m=\u001b[35mtorch\u001b[0m.int32\u001b[1m)\u001b[0m, \u001b[33mdtype\u001b[0m=\u001b[35mtorch\u001b[0m.quint8, \u001b[33mquant_min\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mquant_max\u001b[0m=\u001b[1;36m127\u001b[0m, \u001b[33mqscheme\u001b[0m=\u001b[35mtorch\u001b[0m.per_tensor_affine, \n",
       "\u001b[33mreduce_range\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
       "      \u001b[1m(\u001b[0mactivation_post_process\u001b[1m)\u001b[0m: \u001b[1;35mMovingAverageMinMaxObserver\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmin_val\u001b[0m=\u001b[35minf\u001b[0m, \u001b[33mmax_val\u001b[0m=-inf\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33min_features\u001b[0m=\u001b[1;36m5\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
       "    \u001b[1m(\u001b[0mweight_fake_quant\u001b[1m)\u001b[0m: \u001b[1;35mFusedMovingAvgObsFakeQuantize\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[33mfake_quant_enabled\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mobserver_enabled\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mscale\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m.\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mzero_point\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m, \n",
       "\u001b[33mdtype\u001b[0m=\u001b[35mtorch\u001b[0m.int32\u001b[1m)\u001b[0m, \u001b[33mdtype\u001b[0m=\u001b[35mtorch\u001b[0m.qint8, \u001b[33mquant_min\u001b[0m=\u001b[1;36m-128\u001b[0m, \u001b[33mquant_max\u001b[0m=\u001b[1;36m127\u001b[0m, \u001b[33mqscheme\u001b[0m=\u001b[35mtorch\u001b[0m.per_channel_symmetric, \n",
       "\u001b[33mreduce_range\u001b[0m=\u001b[3;91mFalse\u001b[0m\n",
       "      \u001b[1m(\u001b[0mactivation_post_process\u001b[1m)\u001b[0m: \u001b[1;35mMovingAveragePerChannelMinMaxObserver\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmin_val\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mmax_val\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mactivation_post_process\u001b[1m)\u001b[0m: \u001b[1;35mFusedMovingAvgObsFakeQuantize\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[33mfake_quant_enabled\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mobserver_enabled\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mscale\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m.\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mzero_point\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m, \n",
       "\u001b[33mdtype\u001b[0m=\u001b[35mtorch\u001b[0m.int32\u001b[1m)\u001b[0m, \u001b[33mdtype\u001b[0m=\u001b[35mtorch\u001b[0m.quint8, \u001b[33mquant_min\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mquant_max\u001b[0m=\u001b[1;36m127\u001b[0m, \u001b[33mqscheme\u001b[0m=\u001b[35mtorch\u001b[0m.per_tensor_affine, \n",
       "\u001b[33mreduce_range\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
       "      \u001b[1m(\u001b[0mactivation_post_process\u001b[1m)\u001b[0m: \u001b[1;35mMovingAverageMinMaxObserver\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmin_val\u001b[0m=\u001b[35minf\u001b[0m, \u001b[33mmax_val\u001b[0m=-inf\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mDeQuantStub\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    torch.ao.quantization.QuantStub(),\n",
    "    nn.Linear( 5 , 5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear( 5 , 10 ), \n",
    "    torch.ao.quantization.DeQuantStub())\n",
    "print( model)\n",
    "\n",
    "model.qconfig = torch.ao.quantization.get_default_qat_qconfig(\"fbgemm\")\n",
    "\n",
    "torch.ao.quantization.prepare_qat(model , inplace = True   )\n",
    "\n",
    "print( model )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.8817</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.4927</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.1196</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2639</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.5099</span><span style=\"font-weight: bold\">]]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m-0.8817\u001b[0m, \u001b[1;36m-0.4927\u001b[0m, \u001b[1;36m-0.1196\u001b[0m,  \u001b[1;36m0.2639\u001b[0m, \u001b[1;36m-0.5099\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0502</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1407</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0804</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3467</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0100</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3065</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.1206</span>,\n",
       "          <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.2914</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0553</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2612</span><span style=\"font-weight: bold\">]]]</span>,\n",
       "       <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">FusedMovingAvgObsFqHelperBackward0</span><span style=\"font-weight: bold\">&gt;)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m-0.0502\u001b[0m,  \u001b[1;36m0.1407\u001b[0m, \u001b[1;36m-0.0804\u001b[0m,  \u001b[1;36m0.3467\u001b[0m, \u001b[1;36m-0.0100\u001b[0m,  \u001b[1;36m0.3065\u001b[0m, \u001b[1;36m-0.1206\u001b[0m,\n",
       "          \u001b[1;36m-0.2914\u001b[0m, \u001b[1;36m-0.0553\u001b[0m,  \u001b[1;36m0.2612\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mFusedMovingAvgObsFqHelperBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Sequential</span><span style=\"font-weight: bold\">(</span>\n",
       "  <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">QuantStub</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"font-weight: bold\">(</span>activation_post_process<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">FusedMovingAvgObsFakeQuantize</span><span style=\"font-weight: bold\">(</span>\n",
       "      <span style=\"color: #808000; text-decoration-color: #808000\">fake_quant_enabled</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">])</span>, <span style=\"color: #808000; text-decoration-color: #808000\">observer_enabled</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">])</span>, <span style=\"color: #808000; text-decoration-color: #808000\">scale</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0090</span><span style=\"font-weight: bold\">])</span>, <span style=\"color: #808000; text-decoration-color: #808000\">zero_point</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">98</span><span style=\"font-weight: bold\">]</span>,\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">dtype</span>=<span style=\"color: #800080; text-decoration-color: #800080\">torch</span>.int32<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dtype</span>=<span style=\"color: #800080; text-decoration-color: #800080\">torch</span>.quint8, <span style=\"color: #808000; text-decoration-color: #808000\">quant_min</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">quant_max</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">127</span>, <span style=\"color: #808000; text-decoration-color: #808000\">qscheme</span>=<span style=\"color: #800080; text-decoration-color: #800080\">torch</span>.per_tensor_affine, \n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">reduce_range</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "      <span style=\"font-weight: bold\">(</span>activation_post_process<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MovingAverageMinMaxObserver</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">min_val</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.8817196488380432</span>, \n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">max_val</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.26394128799438477</span><span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "    <span style=\"font-weight: bold\">(</span>weight_fake_quant<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">FusedMovingAvgObsFakeQuantize</span><span style=\"font-weight: bold\">(</span>\n",
       "      <span style=\"color: #808000; text-decoration-color: #808000\">fake_quant_enabled</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">])</span>, <span style=\"color: #808000; text-decoration-color: #808000\">observer_enabled</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">])</span>, <span style=\"color: #808000; text-decoration-color: #808000\">scale</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0027</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0016</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0035</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0027</span>, \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0028</span><span style=\"font-weight: bold\">])</span>, <span style=\"color: #808000; text-decoration-color: #808000\">zero_point</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dtype</span>=<span style=\"color: #800080; text-decoration-color: #800080\">torch</span>.int32<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dtype</span>=<span style=\"color: #800080; text-decoration-color: #800080\">torch</span>.qint8, <span style=\"color: #808000; text-decoration-color: #808000\">quant_min</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">quant_max</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">127</span>, \n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">qscheme</span>=<span style=\"color: #800080; text-decoration-color: #800080\">torch</span>.per_channel_symmetric, <span style=\"color: #808000; text-decoration-color: #808000\">reduce_range</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "      <span style=\"font-weight: bold\">(</span>activation_post_process<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MovingAveragePerChannelMinMaxObserver</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">min_val</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.2244</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0561</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.4467</span>, \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.3462</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.3555</span><span style=\"font-weight: bold\">])</span>, <span style=\"color: #808000; text-decoration-color: #808000\">max_val</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3482</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2076</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4098</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2362</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1118</span><span style=\"font-weight: bold\">]))</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">(</span>activation_post_process<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">FusedMovingAvgObsFakeQuantize</span><span style=\"font-weight: bold\">(</span>\n",
       "      <span style=\"color: #808000; text-decoration-color: #808000\">fake_quant_enabled</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">])</span>, <span style=\"color: #808000; text-decoration-color: #808000\">observer_enabled</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">])</span>, <span style=\"color: #808000; text-decoration-color: #808000\">scale</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0052</span><span style=\"font-weight: bold\">])</span>, <span style=\"color: #808000; text-decoration-color: #808000\">zero_point</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">69</span><span style=\"font-weight: bold\">]</span>,\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">dtype</span>=<span style=\"color: #800080; text-decoration-color: #800080\">torch</span>.int32<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dtype</span>=<span style=\"color: #800080; text-decoration-color: #800080\">torch</span>.quint8, <span style=\"color: #808000; text-decoration-color: #808000\">quant_min</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">quant_max</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">127</span>, <span style=\"color: #808000; text-decoration-color: #808000\">qscheme</span>=<span style=\"color: #800080; text-decoration-color: #800080\">torch</span>.per_tensor_affine, \n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">reduce_range</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "      <span style=\"font-weight: bold\">(</span>activation_post_process<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MovingAverageMinMaxObserver</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">min_val</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.3596686124801636</span>, \n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">max_val</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.30444252490997314</span><span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ReLU</span><span style=\"font-weight: bold\">()</span>\n",
       "  <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "    <span style=\"font-weight: bold\">(</span>weight_fake_quant<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">FusedMovingAvgObsFakeQuantize</span><span style=\"font-weight: bold\">(</span>\n",
       "      <span style=\"color: #808000; text-decoration-color: #808000\">fake_quant_enabled</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">])</span>, <span style=\"color: #808000; text-decoration-color: #808000\">observer_enabled</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">])</span>, <span style=\"color: #808000; text-decoration-color: #808000\">scale</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0031</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0033</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0030</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0019</span>, \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0030</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0026</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0032</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0033</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0034</span>,\n",
       "              <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0019</span><span style=\"font-weight: bold\">])</span>, <span style=\"color: #808000; text-decoration-color: #808000\">zero_point</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dtype</span>=<span style=\"color: #800080; text-decoration-color: #800080\">torch</span>.int32<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dtype</span>=<span style=\"color: #800080; text-decoration-color: #800080\">torch</span>.qint8, \n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">quant_min</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">quant_max</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">127</span>, <span style=\"color: #808000; text-decoration-color: #808000\">qscheme</span>=<span style=\"color: #800080; text-decoration-color: #800080\">torch</span>.per_channel_symmetric, <span style=\"color: #808000; text-decoration-color: #808000\">reduce_range</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "      <span style=\"font-weight: bold\">(</span>activation_post_process<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MovingAveragePerChannelMinMaxObserver</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">min_val</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0068</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.4262</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.3818</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.2456</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.1737</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.3336</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.4121</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.4166</span>,\n",
       "                <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.3722</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.2402</span><span style=\"font-weight: bold\">])</span>, <span style=\"color: #808000; text-decoration-color: #808000\">max_val</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3994</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3824</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2180</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2366</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3865</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1615</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2880</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2146</span>,\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4348</span>,\n",
       "                <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1583</span><span style=\"font-weight: bold\">])</span>\n",
       "      <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">(</span>activation_post_process<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">FusedMovingAvgObsFakeQuantize</span><span style=\"font-weight: bold\">(</span>\n",
       "      <span style=\"color: #808000; text-decoration-color: #808000\">fake_quant_enabled</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">])</span>, <span style=\"color: #808000; text-decoration-color: #808000\">observer_enabled</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">])</span>, <span style=\"color: #808000; text-decoration-color: #808000\">scale</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0050</span><span style=\"font-weight: bold\">])</span>, <span style=\"color: #808000; text-decoration-color: #808000\">zero_point</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">58</span><span style=\"font-weight: bold\">]</span>,\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">dtype</span>=<span style=\"color: #800080; text-decoration-color: #800080\">torch</span>.int32<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dtype</span>=<span style=\"color: #800080; text-decoration-color: #800080\">torch</span>.quint8, <span style=\"color: #808000; text-decoration-color: #808000\">quant_min</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">quant_max</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">127</span>, <span style=\"color: #808000; text-decoration-color: #808000\">qscheme</span>=<span style=\"color: #800080; text-decoration-color: #800080\">torch</span>.per_tensor_affine, \n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">reduce_range</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "      <span style=\"font-weight: bold\">(</span>activation_post_process<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MovingAverageMinMaxObserver</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">min_val</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.29220107197761536</span>, \n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">max_val</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3458470106124878</span><span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">DeQuantStub</span><span style=\"font-weight: bold\">()</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mQuantStub\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0mactivation_post_process\u001b[1m)\u001b[0m: \u001b[1;35mFusedMovingAvgObsFakeQuantize\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[33mfake_quant_enabled\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mobserver_enabled\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mscale\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.0090\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mzero_point\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m98\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[33mdtype\u001b[0m=\u001b[35mtorch\u001b[0m.int32\u001b[1m)\u001b[0m, \u001b[33mdtype\u001b[0m=\u001b[35mtorch\u001b[0m.quint8, \u001b[33mquant_min\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mquant_max\u001b[0m=\u001b[1;36m127\u001b[0m, \u001b[33mqscheme\u001b[0m=\u001b[35mtorch\u001b[0m.per_tensor_affine, \n",
       "\u001b[33mreduce_range\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
       "      \u001b[1m(\u001b[0mactivation_post_process\u001b[1m)\u001b[0m: \u001b[1;35mMovingAverageMinMaxObserver\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmin_val\u001b[0m=\u001b[1;36m-0.8817196488380432\u001b[0m, \n",
       "\u001b[33mmax_val\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.26394128799438477\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33min_features\u001b[0m=\u001b[1;36m5\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m5\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
       "    \u001b[1m(\u001b[0mweight_fake_quant\u001b[1m)\u001b[0m: \u001b[1;35mFusedMovingAvgObsFakeQuantize\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[33mfake_quant_enabled\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mobserver_enabled\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mscale\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.0027\u001b[0m, \u001b[1;36m0.0016\u001b[0m, \u001b[1;36m0.0035\u001b[0m, \u001b[1;36m0.0027\u001b[0m, \n",
       "\u001b[1;36m0.0028\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mzero_point\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mdtype\u001b[0m=\u001b[35mtorch\u001b[0m.int32\u001b[1m)\u001b[0m, \u001b[33mdtype\u001b[0m=\u001b[35mtorch\u001b[0m.qint8, \u001b[33mquant_min\u001b[0m=\u001b[1;36m-128\u001b[0m, \u001b[33mquant_max\u001b[0m=\u001b[1;36m127\u001b[0m, \n",
       "\u001b[33mqscheme\u001b[0m=\u001b[35mtorch\u001b[0m.per_channel_symmetric, \u001b[33mreduce_range\u001b[0m=\u001b[3;91mFalse\u001b[0m\n",
       "      \u001b[1m(\u001b[0mactivation_post_process\u001b[1m)\u001b[0m: \u001b[1;35mMovingAveragePerChannelMinMaxObserver\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmin_val\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m-0.2244\u001b[0m, \u001b[1;36m-0.0561\u001b[0m, \u001b[1;36m-0.4467\u001b[0m, \n",
       "\u001b[1;36m-0.3462\u001b[0m, \u001b[1;36m-0.3555\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mmax_val\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.3482\u001b[0m, \u001b[1;36m0.2076\u001b[0m, \u001b[1;36m0.4098\u001b[0m, \u001b[1;36m0.2362\u001b[0m, \u001b[1;36m0.1118\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mactivation_post_process\u001b[1m)\u001b[0m: \u001b[1;35mFusedMovingAvgObsFakeQuantize\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[33mfake_quant_enabled\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mobserver_enabled\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mscale\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.0052\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mzero_point\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m69\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[33mdtype\u001b[0m=\u001b[35mtorch\u001b[0m.int32\u001b[1m)\u001b[0m, \u001b[33mdtype\u001b[0m=\u001b[35mtorch\u001b[0m.quint8, \u001b[33mquant_min\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mquant_max\u001b[0m=\u001b[1;36m127\u001b[0m, \u001b[33mqscheme\u001b[0m=\u001b[35mtorch\u001b[0m.per_tensor_affine, \n",
       "\u001b[33mreduce_range\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
       "      \u001b[1m(\u001b[0mactivation_post_process\u001b[1m)\u001b[0m: \u001b[1;35mMovingAverageMinMaxObserver\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmin_val\u001b[0m=\u001b[1;36m-0.3596686124801636\u001b[0m, \n",
       "\u001b[33mmax_val\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.30444252490997314\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33min_features\u001b[0m=\u001b[1;36m5\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
       "    \u001b[1m(\u001b[0mweight_fake_quant\u001b[1m)\u001b[0m: \u001b[1;35mFusedMovingAvgObsFakeQuantize\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[33mfake_quant_enabled\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mobserver_enabled\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mscale\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.0031\u001b[0m, \u001b[1;36m0.0033\u001b[0m, \u001b[1;36m0.0030\u001b[0m, \u001b[1;36m0.0019\u001b[0m, \n",
       "\u001b[1;36m0.0030\u001b[0m, \u001b[1;36m0.0026\u001b[0m, \u001b[1;36m0.0032\u001b[0m, \u001b[1;36m0.0033\u001b[0m, \u001b[1;36m0.0034\u001b[0m,\n",
       "              \u001b[1;36m0.0019\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mzero_point\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mdtype\u001b[0m=\u001b[35mtorch\u001b[0m.int32\u001b[1m)\u001b[0m, \u001b[33mdtype\u001b[0m=\u001b[35mtorch\u001b[0m.qint8, \n",
       "\u001b[33mquant_min\u001b[0m=\u001b[1;36m-128\u001b[0m, \u001b[33mquant_max\u001b[0m=\u001b[1;36m127\u001b[0m, \u001b[33mqscheme\u001b[0m=\u001b[35mtorch\u001b[0m.per_channel_symmetric, \u001b[33mreduce_range\u001b[0m=\u001b[3;91mFalse\u001b[0m\n",
       "      \u001b[1m(\u001b[0mactivation_post_process\u001b[1m)\u001b[0m: \u001b[1;35mMovingAveragePerChannelMinMaxObserver\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmin_val\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m-0.0068\u001b[0m, \u001b[1;36m-0.4262\u001b[0m, \u001b[1;36m-0.3818\u001b[0m, \u001b[1;36m-0.2456\u001b[0m, \u001b[1;36m-0.1737\u001b[0m, \u001b[1;36m-0.3336\u001b[0m, \u001b[1;36m-0.4121\u001b[0m, \u001b[1;36m-0.4166\u001b[0m,\n",
       "                \u001b[1;36m-0.3722\u001b[0m, \u001b[1;36m-0.2402\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mmax_val\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.3994\u001b[0m, \u001b[1;36m0.3824\u001b[0m, \u001b[1;36m0.2180\u001b[0m, \u001b[1;36m0.2366\u001b[0m, \u001b[1;36m0.3865\u001b[0m, \u001b[1;36m0.1615\u001b[0m, \u001b[1;36m0.2880\u001b[0m, \u001b[1;36m0.2146\u001b[0m,\n",
       "\u001b[1;36m0.4348\u001b[0m,\n",
       "                \u001b[1;36m0.1583\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mactivation_post_process\u001b[1m)\u001b[0m: \u001b[1;35mFusedMovingAvgObsFakeQuantize\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[33mfake_quant_enabled\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mobserver_enabled\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mscale\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.0050\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mzero_point\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m58\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[33mdtype\u001b[0m=\u001b[35mtorch\u001b[0m.int32\u001b[1m)\u001b[0m, \u001b[33mdtype\u001b[0m=\u001b[35mtorch\u001b[0m.quint8, \u001b[33mquant_min\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mquant_max\u001b[0m=\u001b[1;36m127\u001b[0m, \u001b[33mqscheme\u001b[0m=\u001b[35mtorch\u001b[0m.per_tensor_affine, \n",
       "\u001b[33mreduce_range\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
       "      \u001b[1m(\u001b[0mactivation_post_process\u001b[1m)\u001b[0m: \u001b[1;35mMovingAverageMinMaxObserver\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmin_val\u001b[0m=\u001b[1;36m-0.29220107197761536\u001b[0m, \n",
       "\u001b[33mmax_val\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.3458470106124878\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mDeQuantStub\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = torch.randn([1, 1, 5])\n",
    "print(  x ) \n",
    "print( model(x))\n",
    "print( model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">QuantStub</span><span style=\"font-weight: bold\">(</span>\n",
       "  <span style=\"font-weight: bold\">(</span>activation_post_process<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">FusedMovingAvgObsFakeQuantize</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">fake_quant_enabled</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">])</span>, <span style=\"color: #808000; text-decoration-color: #808000\">observer_enabled</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">])</span>, <span style=\"color: #808000; text-decoration-color: #808000\">scale</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0090</span><span style=\"font-weight: bold\">])</span>, <span style=\"color: #808000; text-decoration-color: #808000\">zero_point</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">98</span><span style=\"font-weight: bold\">]</span>, \n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">dtype</span>=<span style=\"color: #800080; text-decoration-color: #800080\">torch</span>.int32<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dtype</span>=<span style=\"color: #800080; text-decoration-color: #800080\">torch</span>.quint8, <span style=\"color: #808000; text-decoration-color: #808000\">quant_min</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">quant_max</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">127</span>, <span style=\"color: #808000; text-decoration-color: #808000\">qscheme</span>=<span style=\"color: #800080; text-decoration-color: #800080\">torch</span>.per_tensor_affine, \n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">reduce_range</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "    <span style=\"font-weight: bold\">(</span>activation_post_process<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MovingAverageMinMaxObserver</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">min_val</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.8817196488380432</span>, \n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">max_val</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.26394128799438477</span><span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mQuantStub\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mactivation_post_process\u001b[1m)\u001b[0m: \u001b[1;35mFusedMovingAvgObsFakeQuantize\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mfake_quant_enabled\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mobserver_enabled\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mscale\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.0090\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mzero_point\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m98\u001b[0m\u001b[1m]\u001b[0m, \n",
       "\u001b[33mdtype\u001b[0m=\u001b[35mtorch\u001b[0m.int32\u001b[1m)\u001b[0m, \u001b[33mdtype\u001b[0m=\u001b[35mtorch\u001b[0m.quint8, \u001b[33mquant_min\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mquant_max\u001b[0m=\u001b[1;36m127\u001b[0m, \u001b[33mqscheme\u001b[0m=\u001b[35mtorch\u001b[0m.per_tensor_affine, \n",
       "\u001b[33mreduce_range\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
       "    \u001b[1m(\u001b[0mactivation_post_process\u001b[1m)\u001b[0m: \u001b[1;35mMovingAverageMinMaxObserver\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmin_val\u001b[0m=\u001b[1;36m-0.8817196488380432\u001b[0m, \n",
       "\u001b[33mmax_val\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.26394128799438477\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print( model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">torch.float32\n",
       "</pre>\n"
      ],
      "text/plain": [
       "torch.float32\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">torch.float32\n",
       "</pre>\n"
      ],
      "text/plain": [
       "torch.float32\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">torch.float32\n",
       "</pre>\n"
      ],
      "text/plain": [
       "torch.float32\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = model[0](x)\n",
    "print( y.dtype)\n",
    "y = model[1](y)\n",
    "print( y.dtype)\n",
    "y  = model[2](y)\n",
    "print( y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the prepare QA model to a quantized model\n",
    "model_int8 = torch.ao.quantization.convert(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Sequential</span><span style=\"font-weight: bold\">(</span>\n",
       "  <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Quantize</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">scale</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0090</span><span style=\"font-weight: bold\">])</span>, <span style=\"color: #808000; text-decoration-color: #808000\">zero_point</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">98</span><span style=\"font-weight: bold\">])</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dtype</span>=<span style=\"color: #800080; text-decoration-color: #800080\">torch</span>.quint8<span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">QuantizedLinear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #808000; text-decoration-color: #808000\">scale</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.005229221656918526</span>, <span style=\"color: #808000; text-decoration-color: #808000\">zero_point</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">69</span>, \n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">qscheme</span>=<span style=\"color: #800080; text-decoration-color: #800080\">torch</span>.per_channel_affine<span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ReLU</span><span style=\"font-weight: bold\">()</span>\n",
       "  <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">QuantizedLinear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #808000; text-decoration-color: #808000\">scale</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.005024000536650419</span>, <span style=\"color: #808000; text-decoration-color: #808000\">zero_point</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">58</span>, \n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">qscheme</span>=<span style=\"color: #800080; text-decoration-color: #800080\">torch</span>.per_channel_affine<span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">DeQuantize</span><span style=\"font-weight: bold\">()</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mQuantize\u001b[0m\u001b[1m(\u001b[0m\u001b[33mscale\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.0090\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mzero_point\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m98\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mdtype\u001b[0m=\u001b[35mtorch\u001b[0m.quint8\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mQuantizedLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m5\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m5\u001b[0m, \u001b[33mscale\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.005229221656918526\u001b[0m, \u001b[33mzero_point\u001b[0m=\u001b[1;36m69\u001b[0m, \n",
       "\u001b[33mqscheme\u001b[0m=\u001b[35mtorch\u001b[0m.per_channel_affine\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mReLU\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mQuantizedLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m5\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mscale\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.005024000536650419\u001b[0m, \u001b[33mzero_point\u001b[0m=\u001b[1;36m58\u001b[0m, \n",
       "\u001b[33mqscheme\u001b[0m=\u001b[35mtorch\u001b[0m.per_channel_affine\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mDeQuantize\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print( model_int8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('cleanrl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b8210207dea593cd78a47d19ab578efef95523f0b438f1eecba204cd30d51d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
